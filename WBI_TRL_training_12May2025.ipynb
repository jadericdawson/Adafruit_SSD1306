{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jadericdawson/Adafruit_SSD1306/blob/master/WBI_TRL_training_12May2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m63SIUeBSYHd"
      },
      "source": [
        "\n",
        "Colab Notebook: Fine-tuning with Unsloth GRPO for WBI DoD Proposals\n",
        "This notebook demonstrates how to fine-tune a language model using Unsloth and Group Relative Policy Optimization (GRPO) to generate proposal content for the Wright Brothers Institute (WBI) in response to hypothetical Department of Defense (DoD) solicitations.\n",
        "\n",
        "Phase 1: Setup and Installation\n",
        "First, we install the necessary libraries, primarily Unsloth and its dependencies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX_VBNDUSQe5",
        "outputId": "bf95b6a9-6cac-4aa4-b730-15419d866eea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-icsg5f5p/unsloth_dd455495a7024f11a7d6843a309cec5c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-icsg5f5p/unsloth_dd455495a7024f11a7d6843a309cec5c\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit c281a787b20e1dd564ee10755f9aaa86191b3e0e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth_zoo>=2025.5.1 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.9.20)\n",
            "Requirement already satisfied: transformers!=4.47.0,==4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.51.3)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.0.2)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.31.1)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\n",
            "Requirement already satisfied: bitsandbytes>=0.45.5 in /usr/local/lib/python3.11/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.45.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.5.3)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.1.0)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
            "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Using cached trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.15.2)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.4.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.19.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes>=0.45.5->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Using cached trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "Installing collected packages: trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.17.0\n",
            "    Uninstalling trl-0.17.0:\n",
            "      Successfully uninstalled trl-0.17.0\n",
            "Successfully installed trl-0.15.2\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.8.5.post1)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from vllm) (5.5.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from vllm) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n",
            "Requirement already satisfied: blake3 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.4)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.51.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.51.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm) (0.31.1)\n",
            "Requirement already satisfied: tokenizers>=0.21.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (3.20.3)\n",
            "Requirement already satisfied: fastapi>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.12)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.15)\n",
            "Requirement already satisfied: openai>=1.52.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.77.0)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.11.4)\n",
            "Requirement already satisfied: prometheus_client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.2.1)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.11)\n",
            "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.7.19)\n",
            "Requirement already satisfied: outlines==0.1.11 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.11)\n",
            "Requirement already satisfied: lark==1.2.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.2.2)\n",
            "Requirement already satisfied: xgrammar==0.1.18 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.1.18)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.13.2)\n",
            "Requirement already satisfied: filelock>=3.16.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.18.0)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post5)\n",
            "Requirement already satisfied: pyzmq>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (26.4.0)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n",
            "Requirement already satisfied: gguf>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.16.3)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.0.0)\n",
            "Requirement already satisfied: mistral_common>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from mistral_common[opencv]>=1.5.4->vllm) (1.5.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.11.0.86)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.1)\n",
            "Requirement already satisfied: compressed-tensors==0.9.3 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.9.3)\n",
            "Requirement already satisfied: depyf==0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.18.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from vllm) (3.1.1)\n",
            "Requirement already satisfied: watchfiles in /usr/local/lib/python3.11/dist-packages (from vllm) (1.0.5)\n",
            "Requirement already satisfied: python-json-logger in /usr/local/lib/python3.11/dist-packages (from vllm) (3.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from vllm) (1.15.2)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from vllm) (1.11.1.4)\n",
            "Requirement already satisfied: opentelemetry-sdk<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-api<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp<1.27.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.4.8)\n",
            "Requirement already satisfied: numba==0.61.2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.61.2)\n",
            "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.46.0)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio==2.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0+cu124)\n",
            "Requirement already satisfied: xformers==0.0.29.post2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.29.post2)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from depyf==0.18.0->vllm) (0.3.7)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba==0.61.2->vllm) (0.44.0)\n",
            "Requirement already satisfied: interegular in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
            "Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (20250224)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.11/dist-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->vllm) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.7)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
            "Requirement already satisfied: email-validator>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (24.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.30.0->huggingface-hub[hf_xet]>=0.30.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.52.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.26.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm) (0.47b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.4.26)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.51.1->vllm) (0.5.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.20.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.3)\n",
            "Requirement already satisfied: rich-toolkit>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.14.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.1.2)\n",
            "Installation complete.\n",
            "IMPORTANT: You MUST RESTART THE RUNTIME now for all changes to take effect.\n",
            "Runtime > Restart Runtime (or Ctrl+M .)\n"
          ]
        }
      ],
      "source": [
        "#@title 1.1 Install Libraries\n",
        "# Install Unsloth first - let it pull its specific compatible dependencies like TRL\n",
        "# Use the latest recommended command from Unsloth's GitHub for Colab\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "# !pip install unsloth # Alternative if the above causes issues, but git install is often preferred\n",
        "\n",
        "# Upgrade Pillow separately (usually safe)\n",
        "!pip install --upgrade pillow\n",
        "\n",
        "# Install other dependencies - Check Unsloth docs if specific versions are needed\n",
        "# Often Unsloth's install handles PEFT, Accelerate, Bitsandbytes correctly.\n",
        "# Avoid explicitly upgrading TRL here. If you need specific versions of others, pin them:\n",
        "# Example: !pip install \"peft==0.11.1\" \"accelerate==0.30.1\" # <== FIND CORRECT VERSIONS IF NEEDED\n",
        "\n",
        "# Install vLLM if you plan to use it (might have its own dependencies)\n",
        "!pip install vllm\n",
        "\n",
        "print(\"Installation complete.\")\n",
        "print(\"IMPORTANT: You MUST RESTART THE RUNTIME now for all changes to take effect.\")\n",
        "print(\"Runtime > Restart Runtime (or Ctrl+M .)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2Twaz1GSjEd"
      },
      "source": [
        "Text Cell:\n",
        "After running the cell above, restart your Colab runtime by navigating to \"Runtime\" > \"Restart Runtime\" (or using the shortcut Ctrl+M .). This is crucial for the newly installed libraries to be correctly loaded.\n",
        "\n",
        "Phase 2: Model Loading and LoRA Configuration with Unsloth\n",
        "We'll load a base model efficiently using Unsloth's FastModel and then apply LoRA (Low-Rank Adaptation) for parameter-efficient fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWDNDiirSlQO",
        "outputId": "efc4995e-822e-43ef-fe54-d3d3b8658aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 05-12 16:56:19 [importing.py:53] Triton module has been replaced with a placeholder.\n",
            "INFO 05-12 16:56:19 [__init__.py:239] Automatically detected platform cuda.\n",
            "Loading model: unsloth/gemma-3-1b-it-bnb-4bit\n",
            "==((====))==  Unsloth 2025.5.1: Fast Gemma3 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Model loaded.\n",
            "Configuring LoRA adapters...\n",
            "Unsloth: Making `model.base_model.model.model` require gradients\n",
            "LoRA adapters configured.\n",
            "trainable params: 13,045,760 || all params: 1,012,931,712 || trainable%: 1.2879\n"
          ]
        }
      ],
      "source": [
        "#@title 2.1 Load Model and Configure LoRA\n",
        "import torch\n",
        "from unsloth import FastModel\n",
        "# from peft import LoraConfig # Unsloth's FastModel.get_peft_model can handle this internally\n",
        "\n",
        "# --- Configuration ---\n",
        "max_seq_length = 2048  # Max sequence length for the model (prompts + completions)\n",
        "load_in_4bit = True    # Use 4-bit quantization for memory efficiency on Colab T4\n",
        "\n",
        "# Model Selection: Choose a suitable instruction-tuned model from Unsloth's offerings.\n",
        "# Smaller models like Gemma-1B/3B or Llama-3.1-3B are good for Colab.\n",
        "# Using a pre-quantized 4-bit model from Unsloth is recommended.\n",
        "model_name = \"unsloth/gemma-3-1b-it-bnb-4bit\"\n",
        "# Alternatives:\n",
        "# model_name = \"unsloth/gemma-1b-it-bnb-4bit\" # Even smaller Gemma\n",
        "# model_name = \"unsloth/Llama-3.1-8B-bnb-4bit\" # Larger, might require Colab Pro or careful memory management\n",
        "\n",
        "print(f\"Loading model: {model_name}\")\n",
        "model, tokenizer = FastModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    # token=\"hf_YOUR_TOKEN_HERE\",  # Add your Hugging Face token if using a gated model\n",
        ")\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "# --- Add LoRA Adapters ---\n",
        "# Configure LoRA using Unsloth's helper function for PEFT.\n",
        "print(\"Configuring LoRA adapters...\")\n",
        "model = FastModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # LoRA rank (e.g., 8, 16, 32).\n",
        "    lora_alpha=16,  # Scaling factor, often equal to r or 2*r.\n",
        "    lora_dropout=0.05,  # Dropout for LoRA layers.\n",
        "    bias=\"none\",  # Type of bias training. \"none\" is common for LoRA.\n",
        "    use_gradient_checkpointing=\"unsloth\", # Unsloth's method for memory saving.\n",
        "    random_state=3407, # For reproducibility.\n",
        "    target_modules=[ # Specify layers to apply LoRA. Unsloth might auto-detect.\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        ")\n",
        "print(\"LoRA adapters configured.\")\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VctDb0QRSmSl"
      },
      "source": [
        "Phase 3: Data Preparation for WBI DoD Proposals\n",
        "This is a critical step where we define the structure for our \"thinking\" LLM and prepare a dataset based on WBI's information and hypothetical DoD solicitation prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "f845bcac9c9745f0870c37ae40333f91",
            "41348491aa914f4aba163acf23d32897",
            "c3ba29eedc14423b8574c2e114010542",
            "da267cf76c1b4474827271ff284c5eac",
            "c7ff4c5007c54002a98471daa7228959",
            "f3d6eb46690648b49bcf9ece7314e7ba",
            "42e1255321434f618bd5a6fa79724c22",
            "04b07403d3764135b3e399ad9fd9ec45",
            "06dbfc840afd4568a1c300d4c761b0e1",
            "4ca2ea736bd847e58e626e63773b3040",
            "59d746e2c6684ca5bbcf8dd209d12d9e"
          ]
        },
        "id": "IWT-uvtcSpdc",
        "outputId": "7fb09721-62ee-46ee-d605-35b9d4a5b5ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f845bcac9c9745f0870c37ae40333f91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Formatted WBI Training Dataset Example ---\n",
            "Number of examples: 10\n",
            "{'id': 'wbi_dod_001', 'question': \"Describe WBI's methodology for leveraging its Partnership Intermediary Agreement with AFRL to accelerate technology development and transition. Provide examples of collaborative environments WBI utilizes.\", 'expected_keywords': ['PIA', 'AFRL', 'technology transfer', 'Discover, Develop, Deliver', 'collaboration', 'Tec^Edge', 'neutral convener'], 'expected_programs': ['Tec^Edge Innovation and Collaboration Center', 'SDR University Challenge'], 'prompt': [{'content': 'You are an expert assistant for the Wright Brothers Institute (WBI), a non-profit 501(c)(3) innovation intermediary.\\nYour task is to generate content to satisfy Department of Defense (DoD) solicitations by creating proposal sections, showcasing WBI\\'s capabilities, experience, and value.\\nStructure your response as follows:\\n1.  First, provide your thinking process and rationale. Enclose this detailed reasoning within <WBI_THINK_START> and <WBI_THINK_END> tags. In this section, explain how WBI\\'s strengths, past projects, and operational model (like \"Discover, Develop, Deliver\") address the user\\'s request.\\n2.  Second, provide the drafted proposal section text. Enclose this formal text within <WBI_PROPOSAL_SECTION_START> and <WBI_PROPOSAL_SECTION_END> tags.\\n\\nWhen generating content:\\n-   Accurately reflect WBI\\'s mission to accelerate solutions for the warfighter by uniting end-users, technologists, acquirers, and experts from industry and academia.\\n-   Emphasize WBI\\'s cornerstone Partnership Intermediary Agreement (PIA) with the Air Force Research Laboratory (AFRL).\\n-   Incorporate relevant WBI programs (e.g., Software Defined Radio University Challenge, SDR University Challenge, SDR Challenge), partnerships (e.g., AFRL, AFLCMC, NSWC Crane), and core capabilities (e.g., rapid prototyping, technology transfer, commercialization, multi-sector collaboration).\\n-   Highlight WBI\\'s role as a neutral convener and agile facilitator in the Dayton, Ohio, defense ecosystem and beyond.\\n-   Cite specific WBI initiatives or achievements as evidence where appropriate, drawing from WBI\\'s established record and programs.\\n', 'role': 'system'}, {'content': \"Describe WBI's methodology for leveraging its Partnership Intermediary Agreement with AFRL to accelerate technology development and transition. Provide examples of collaborative environments WBI utilizes.\", 'role': 'user'}], 'answer': {'id': 'wbi_dod_001', 'reference_keywords': ['PIA', 'AFRL', 'technology transfer', 'Discover, Develop, Deliver', 'collaboration', 'Tec^Edge', 'neutral convener'], 'reference_programs': ['Tec^Edge Innovation and Collaboration Center', 'SDR University Challenge']}}\n",
            "--- End of Dataset Example ---\n"
          ]
        }
      ],
      "source": [
        "#@title 3.1 Define Custom Tags, WBI Info, System Prompt, and Dataset\n",
        "from datasets import Dataset\n",
        "import random # Not used in this snippet, but often useful for dataset manipulation\n",
        "\n",
        "# --- Define Custom Tags for WBI Proposal Structure ---\n",
        "WBI_THINK_START_TAG = \"<WBI_THINK_START>\"\n",
        "WBI_THINK_END_TAG = \"<WBI_THINK_END>\"\n",
        "WBI_PROPOSAL_SECTION_START_TAG = \"<WBI_PROPOSAL_SECTION_START>\"\n",
        "WBI_PROPOSAL_SECTION_END_TAG = \"<WBI_PROPOSAL_SECTION_END>\"\n",
        "\n",
        "# --- Expanded WBI Core Concepts & Program Examples (for rewards and system prompt context) ---\n",
        "# Derived comprehensively from the WBI company information you provided.\n",
        "\n",
        "WBI_CORE_CONCEPTS_FOR_REWARD = [\n",
        "    # Names & Aliases\n",
        "    \"Wright Brothers Institute\", \"WBI\",\n",
        "    # Key Partners & Entities\n",
        "    \"AFRL\", \"Air Force Research Laboratory\", \"$4 billion technology powerhouse\", \"AFRL/RX\", \"AFRL's Materials and Manufacturing Directorate\",\n",
        "    \"AFLCMC\", \"Air Force Life Cycle Management Center\", \"AFMC\", \"Air Force Materiel Command\",\n",
        "    \"AFIMSC\", \"Air Force Installation and Mission Support Center\", \"AFICC\", \"Air Force Installation Contracting Center\",\n",
        "    \"NSWC Crane\", \"Naval Surface Warfare Center Crane Division\", \"US Navy\",\n",
        "    \"Universities\", \"University of Dayton\", \"Wright State University\", \"Purdue University\", \"University of Cincinnati\", \"Miami University\",\n",
        "    \"Industry\", \"Industry partners\", \"Small Businesses\", \"Start-ups\", \"SBIR companies\",\n",
        "    \"The Entrepreneurs' Center\", \"The Collaboratory\", \"Dayton Development Coalition\", \"National Instruments\", \"Emerson\", \"FDA\",\n",
        "    # Locations & Facilities\n",
        "    \"Dayton\", \"Ohio\", \"Wright-Patterson Air Force Base\", \"WPAFB\",\n",
        "    \"WBI Headquarters\", \"5000 Springfield Street\", \"Tec^Edge Innovation and Collaboration Center\", \"Tec^Edge\",\n",
        "    \"IDEA Lab\", \"Discovery Labs\", \"high tech 'monster garage'\", \"25,000 sq. ft. facility\",\n",
        "    \"Proving Ground\", \"Works\", \"105 Janney Road\", \"The Hub\", \"444 East Second St.\",\n",
        "    # Organizational & Legal\n",
        "    \"Non-profit\", \"501(c)(3)\", \"Tax-Exempt since May 2003\", \"Founded 2002\",\n",
        "    \"Partnership Intermediary Agreement\", \"PIA\", \"First PIA with Air Force\",\n",
        "    \"Neutral convener\", \"Agile facilitator\", \"Innovation intermediary\",\n",
        "    \"Independent Board of Trustees\", \"Financial stewardship\", \"Program service revenue\",\n",
        "    # Mission, Vision & Framework\n",
        "    \"Discover, Develop, Deliver\", \"Accelerate solutions\", \"Cutting-edge solutions\", \"Warfighter solutions\",\n",
        "    \"Empower and enhance decision-making\", \"Shap[e] the Future of Defense\",\n",
        "    \"Transferring real-world solutions and capabilities to the warfighter\", \"First stop for innovation\",\n",
        "    \"Uniting stakeholders\", \"end-users\", \"technologists\", \"acquirers\", \"experts\", \"Subject Matter Experts\", \"SMEs\",\n",
        "    \"Bridging the 'valley of death'\", \"Unexpected and undiscovered Warfighter Solutions\",\n",
        "    # Capabilities & Activities\n",
        "    \"Spearheading defense innovation\", \"Multi-sector collaboration\", \"Collaborative environments\",\n",
        "    \"Technology transfer\", \"Tech transfer\", \"T3\", \"Technology transition\", \"Commercialization\",\n",
        "    \"Spin-in\", \"Spin-out\", \"Rapid prototyping\", \"Workforce development\",\n",
        "    \"Disruptive innovation processes\", \"Ecosystem building\", \"WBI Ecosystem\",\n",
        "    \"Problem-solving methodologies\", \"sprints\", \"open innovation\", \"Divergent Collaboration tool\",\n",
        "    \"Market analytics\", \"Manpower solutions\", \"Predictive modeling\", \"Inter-service collaboration\",\n",
        "    \"Technology scouting\", \"IP bundling\", \"Licensing opportunities\",\n",
        "    # Economic & Regional Impact\n",
        "    \"Regional economic development\", \"Stimulating industrial base\", \"Dayton aerospace advancement\",\n",
        "    # General Strategic Terms\n",
        "    \"National security\", \"Defense innovation ecosystem\", \"Complex challenges\", \"Operational capabilities\",\n",
        "    \"Emerging technologies\", \"AI\", \"Artificial Intelligence\", \"quantum computing\", \"advanced space technologies\", \"synthetic biology\"\n",
        "]\n",
        "\n",
        "WBI_PROGRAM_EXAMPLES_FOR_REWARD = [\n",
        "    # Flagship & Recurring Programs\n",
        "    \"Software Defined Radio University Challenge\", \"SDR University Challenge\", \"SDR Challenge\",\n",
        "    \"Tec^Edge Innovation and Collaboration Center\", \"Tec^Edge\", # Also a facility, but used programmatically\n",
        "    \"DoD SkillBridge Program\", \"SkillBridge\",\n",
        "    \"TECH-ARTS Collaboration\", \"TECH-ARTS\",\n",
        "    \"Collaboration Accelerator\",\n",
        "    \"AFRL Small Business Hub\", \"Small Business Hub\",\n",
        "    \"Lunch & Learn Program\",\n",
        "    # Specific Events & Initiatives\n",
        "    \"Demystifying the Acquisition Process\",\n",
        "    \"Small Business Infrastructure and matchmaking Collider\", \"Collider events\",\n",
        "    \"Developing Elite Acquisition Workforce\",\n",
        "    \"AI Manufacturing Network\", # WBI supported setting up collaborative environment\n",
        "    \"AFRL Manpower Analytics\",\n",
        "    \"Summer of Innovation\", # Activity type WBI supports\n",
        "    \"Accelerators\", # Commercialization service/program type\n",
        "    \"AFRL Regional Network\", # Pilot initiative\n",
        "    # Methodologies named as initiatives/tools\n",
        "    \"Divergent Collaboration\" # Ideation tool developed\n",
        "]\n",
        "\n",
        "# --- Create a System Prompt for WBI Proposal Generation ---\n",
        "# This guides the LLM on its role, expected output format, and knowledge domain.\n",
        "wbi_system_prompt_content = f\"\"\"You are an expert assistant for the Wright Brothers Institute (WBI), a non-profit 501(c)(3) innovation intermediary.\n",
        "Your task is to generate content to satisfy Department of Defense (DoD) solicitations by creating proposal sections, showcasing WBI's capabilities, experience, and value.\n",
        "Structure your response as follows:\n",
        "1.  First, provide your thinking process and rationale. Enclose this detailed reasoning within {WBI_THINK_START_TAG} and {WBI_THINK_END_TAG} tags. In this section, explain how WBI's strengths, past projects, and operational model (like \"Discover, Develop, Deliver\") address the user's request.\n",
        "2.  Second, provide the drafted proposal section text. Enclose this formal text within {WBI_PROPOSAL_SECTION_START_TAG} and {WBI_PROPOSAL_SECTION_END_TAG} tags.\n",
        "\n",
        "When generating content:\n",
        "-   Accurately reflect WBI's mission to accelerate solutions for the warfighter by uniting end-users, technologists, acquirers, and experts from industry and academia.\n",
        "-   Emphasize WBI's cornerstone Partnership Intermediary Agreement (PIA) with the Air Force Research Laboratory (AFRL).\n",
        "-   Incorporate relevant WBI programs (e.g., {', '.join(WBI_PROGRAM_EXAMPLES_FOR_REWARD[:3])}), partnerships (e.g., AFRL, AFLCMC, NSWC Crane), and core capabilities (e.g., rapid prototyping, technology transfer, commercialization, multi-sector collaboration).\n",
        "-   Highlight WBI's role as a neutral convener and agile facilitator in the Dayton, Ohio, defense ecosystem and beyond.\n",
        "-   Cite specific WBI initiatives or achievements as evidence where appropriate, drawing from WBI's established record and programs.\n",
        "\"\"\"\n",
        "\n",
        "# --- Create a Dataset of DoD-Style Prompts and Reference Data for Rewards ---\n",
        "# These prompts simulate questions from a DoD solicitation.\n",
        "# `expected_keywords` and `expected_programs` are used by reward functions.\n",
        "# For effective fine-tuning, you'll need a much larger and more diverse dataset (hundreds or thousands of examples).\n",
        "wbi_dod_prompts_with_references = [\n",
        "    {\n",
        "        \"id\": \"wbi_dod_001\",\n",
        "        \"question\": \"Describe WBI's methodology for leveraging its Partnership Intermediary Agreement with AFRL to accelerate technology development and transition. Provide examples of collaborative environments WBI utilizes.\",\n",
        "        \"expected_keywords\": [\"PIA\", \"AFRL\", \"technology transfer\", \"Discover, Develop, Deliver\", \"collaboration\", \"Tec^Edge\", \"neutral convener\"],\n",
        "        \"expected_programs\": [\"Tec^Edge Innovation and Collaboration Center\", \"SDR University Challenge\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_002\",\n",
        "        \"question\": \"Explain WBI's approach to enhancing Air Force operational capabilities through talent development and fostering novel problem-solving methodologies.\",\n",
        "        \"expected_keywords\": [\"SkillBridge\", \"workforce development\", \"TECH-ARTS\", \"SDR Challenge\", \"Collaboration Accelerator\", \"problem-solving\", \"Divergent Collaboration\"],\n",
        "        \"expected_programs\": [\"DoD SkillBridge Program\", \"TECH-ARTS Collaboration\", \"SDR University Challenge\", \"Developing Elite Acquisition Workforce\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_003\",\n",
        "        \"question\": \"Detail WBI's experience in engaging with the Air Force Life Cycle Management Center (AFLCMC) and supporting small business participation in defense contracts.\",\n",
        "        \"expected_keywords\": [\"AFLCMC\", \"Small Business Hub\", \"Collider events\", \"acquisition process\", \"matchmaking\", \"SBIR companies\"],\n",
        "        \"expected_programs\": [\"AFRL Small Business Hub\", \"Demystifying the Acquisition Process\", \"Small Business Infrastructure and matchmaking Collider\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_004\",\n",
        "        \"question\": \"Outline WBI's contribution to the Dayton regional defense industrial base and its strategy for technology commercialization benefiting both defense and commercial markets.\",\n",
        "        \"expected_keywords\": [\"Dayton\", \"regional economic development\", \"commercialization\", \"dual-use\", \"industrial base\", \"The Entrepreneurs' Center\", \"spin-out\", \"spin-in\"],\n",
        "        \"expected_programs\": [\"Accelerators\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_005\",\n",
        "        \"question\": \"How does WBI's 'Discover, Develop, Deliver' framework specifically ensure that solutions are ready for acquisition and meet warfighter needs?\",\n",
        "        \"expected_keywords\": [\"Discover\", \"Develop\", \"Deliver\", \"acquisition readiness\", \"warfighter needs\", \"risk minimization\", \"SMEs\", \"valley of death\"],\n",
        "        \"expected_programs\": []\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_006\",\n",
        "        \"question\": \"Discuss WBI's role in facilitating inter-service collaboration, citing an example such as its PIA with NSWC Crane.\",\n",
        "        \"expected_keywords\": [\"NSWC Crane\", \"PIA\", \"inter-service\", \"Navy\", \"Air Force\", \"joint commercialization\", \"IP bundling\", \"Force Multiplier\"],\n",
        "        \"expected_programs\": [\"NSWC Crane PIA\"] # This is the key program example\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_007\",\n",
        "        \"question\": \"What are the key features and benefits of WBI's Tec^Edge Innovation and Collaboration Center for AFRL and its partners?\",\n",
        "        \"expected_keywords\": [\"Tec^Edge\", \"IDEA Lab\", \"Discovery Labs\", \"rapid prototyping\", \"monster garage\", \"R&D collaborations\", \"25,000 sq. ft. facility\", \"subject matter experts\"],\n",
        "        \"expected_programs\": [\"Tec^Edge Innovation and Collaboration Center\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_008\",\n",
        "        \"question\": \"How does WBI's non-profit status and role as a neutral convener benefit its mission to unite diverse stakeholders for defense innovation?\",\n",
        "        \"expected_keywords\": [\"non-profit\", \"501(c)(3)\", \"neutral convener\", \"uniting stakeholders\", \"industry\", \"academia\", \"government\", \"trust\", \"open interchanges\"],\n",
        "        \"expected_programs\": []\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_009\",\n",
        "        \"question\": \"Describe WBI's approach to technology scouting and commercialization, including both 'spin-in' and 'spin-out' strategies.\",\n",
        "        \"expected_keywords\": [\"technology scouting\", \"commercialization\", \"spin-in\", \"spin-out\", \"Leveraging the Lab\", \"Leveraging the Marketplace\", \"Accelerators\"],\n",
        "        \"expected_programs\": [\"Accelerators\"]\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"wbi_dod_010\",\n",
        "        \"question\": \"Explain WBI's involvement in workforce development initiatives beyond the DoD SkillBridge program, such as supporting the AFMC/AFLCMC acquisition workforce.\",\n",
        "        \"expected_keywords\": [\"workforce development\", \"Developing Elite Acquisition Workforce\", \"AFMC\", \"AFLCMC\", \"talent pipeline\", \"STEM\"],\n",
        "        \"expected_programs\": [\"Developing Elite Acquisition Workforce\", \"SDR University Challenge\", \"SkillBridge\"]\n",
        "    }\n",
        "]\n",
        "\n",
        "# --- Map Raw Data to GRPOTrainer Format ---\n",
        "# 'prompt' will be fed to the model (as a chat interaction).\n",
        "# 'answer' dictionary will be passed to reward functions for checking against generated completions.\n",
        "def format_wbi_dataset_for_grpo(example):\n",
        "    return {\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": wbi_system_prompt_content},\n",
        "            {\"role\": \"user\", \"content\": example[\"question\"]},\n",
        "        ],\n",
        "        \"answer\": {  # This 'answer' dict is passed to reward functions\n",
        "            \"id\": example[\"id\"],\n",
        "            \"reference_keywords\": example.get(\"expected_keywords\", []), # Use .get for safety\n",
        "            \"reference_programs\": example.get(\"expected_programs\", []), # Use .get for safety\n",
        "        }\n",
        "    }\n",
        "\n",
        "train_dataset_wbi = Dataset.from_list(wbi_dod_prompts_with_references).map(format_wbi_dataset_for_grpo)\n",
        "\n",
        "print(\"--- Formatted WBI Training Dataset Example ---\")\n",
        "print(f\"Number of examples: {len(train_dataset_wbi)}\")\n",
        "if len(train_dataset_wbi) > 0:\n",
        "    print(train_dataset_wbi[0])\n",
        "else:\n",
        "    print(\"Dataset is empty. Please add examples to `wbi_dod_prompts_with_references`.\")\n",
        "print(\"--- End of Dataset Example ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GHGV7CFSrS-"
      },
      "source": [
        "Phase 4: Define Custom Reward Functions\n",
        "These functions are the heart of GRPO. They score the LLM's generated outputs based on adherence to our desired format and relevance to WBI's information and the specific prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3eoEvI9SvcJ",
        "outputId": "c16922ea-00ba-4731-d7b9-c19bf00fb37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined 3 reward functions with updated signatures.\n"
          ]
        }
      ],
      "source": [
        "#@title 4.1 Define Reward Functions for WBI DoD Proposals\n",
        "import re\n",
        "\n",
        "# --- Regex to match our desired WBI output format accurately ---\n",
        "# Using [\\s\\S] to match any character including newlines.\n",
        "# Using non-greedy `+?` for content within tags.\n",
        "# Anchoring with `^` and `$` and using `fullmatch` ensures the entire string conforms.\n",
        "wbi_output_format_regex = re.compile(\n",
        "    rf\"^{WBI_THINK_START_TAG}([\\s\\S]+?){WBI_THINK_END_TAG}[\\s\\S]*?\"\n",
        "    rf\"{WBI_PROPOSAL_SECTION_START_TAG}([\\s\\S]+?){WBI_PROPOSAL_SECTION_END_TAG}$\",\n",
        "    flags=re.MULTILINE | re.DOTALL\n",
        ")\n",
        "\n",
        "# --- Helper to extract answer references ---\n",
        "def get_answer_references(kwargs):\n",
        "    \"\"\"Safely extracts the answer references batch from kwargs.\"\"\"\n",
        "    answer_refs = kwargs.get(\"answer\") # Use the dataset column name \"answer\" as the key\n",
        "    if answer_refs is None:\n",
        "        print(\"WARNING: 'answer' key not found in reward_kwargs! Cannot score content.\")\n",
        "        # Return None or an empty list depending on how you want to handle downstream\n",
        "        return None\n",
        "    return answer_refs\n",
        "\n",
        "def reward_wbi_exact_format_adherence(completions, prompts, **kwargs): # Removed answer_references_batch, added **kwargs\n",
        "    \"\"\"\n",
        "    Rewards completions that perfectly match the specified WBI THINK and PROPOSAL_SECTION format\n",
        "    and have substantial content in both sections.\n",
        "    'completions': List of strings (generated outputs).\n",
        "    'prompts': List of prompt inputs for the batch.\n",
        "    'kwargs': Dictionary possibly containing extra dataset columns like 'answer'.\n",
        "    \"\"\"\n",
        "    # NOTE: This specific function doesn't actually NEED answer_references_batch,\n",
        "    # so you could technically just remove it without adding the extraction logic below.\n",
        "    # However, keeping the pattern consistent with the other functions is good practice.\n",
        "    # answer_references_batch = get_answer_references(kwargs) # Extract if needed later\n",
        "\n",
        "    scores = []\n",
        "    for completion_text in completions:\n",
        "        score = 0.0\n",
        "        match = wbi_output_format_regex.fullmatch(completion_text.strip())\n",
        "        if match:\n",
        "            think_content = match.group(1).strip()\n",
        "            proposal_content = match.group(2).strip()\n",
        "            if len(think_content) > 25 and len(proposal_content) > 40:\n",
        "                score += 3.0\n",
        "            elif len(think_content) > 10 or len(proposal_content) > 20:\n",
        "                score += 1.0\n",
        "            else:\n",
        "                score += 0.2\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "def reward_wbi_approximate_format_presence(completions, prompts, **kwargs): # Removed answer_references_batch, added **kwargs\n",
        "    \"\"\"\n",
        "    Rewards completions for the presence of individual tags, even if the overall format isn't perfect.\n",
        "    Penalizes if tags are missing or duplicated, encouraging proper tag usage.\n",
        "    \"\"\"\n",
        "    # NOTE: This function also doesn't NEED answer_references_batch.\n",
        "    # answer_references_batch = get_answer_references(kwargs) # Extract if needed\n",
        "\n",
        "    scores = []\n",
        "    all_defined_tags = [WBI_THINK_START_TAG, WBI_THINK_END_TAG, WBI_PROPOSAL_SECTION_START_TAG, WBI_PROPOSAL_SECTION_END_TAG]\n",
        "    for completion_text in completions:\n",
        "        score = 0.0\n",
        "        for tag in all_defined_tags:\n",
        "            tag_count = completion_text.count(tag)\n",
        "            if tag_count == 1:\n",
        "                score += 0.5\n",
        "            elif tag_count > 1:\n",
        "                score -= 0.5\n",
        "        scores.append(score)\n",
        "    return scores\n",
        "\n",
        "def reward_wbi_content_and_evidence(completions, prompts, **kwargs): # Removed answer_references_batch, added **kwargs\n",
        "    \"\"\"\n",
        "    Rewards completions for including relevant WBI keywords (general and prompt-specific)\n",
        "    and specific WBI program examples within the PROPOSAL_SECTION.\n",
        "    Also gives minor rewards for keywords in THINK section.\n",
        "    \"\"\"\n",
        "    answer_references_batch = get_answer_references(kwargs) # EXTRACT THE DATA HERE\n",
        "    if answer_references_batch is None:\n",
        "         # If data is missing, return default low scores as we can't evaluate content\n",
        "         return [-2.0] * len(completions) # Penalize slightly or return 0\n",
        "\n",
        "    batch_scores = []\n",
        "    # Ensure length matches completions in case extraction failed partially (though get_answer_references handles full failure)\n",
        "    if len(answer_references_batch) != len(completions):\n",
        "        print(f\"WARNING: Mismatch between completions ({len(completions)}) and answer_references ({len(answer_references_batch)}) lengths.\")\n",
        "        # Handle mismatch, e.g., return default scores\n",
        "        return [-2.0] * len(completions)\n",
        "\n",
        "    for i, completion_text in enumerate(completions):\n",
        "        current_score = 0.0\n",
        "        # Get the 'answer' reference dictionary for this specific completion.\n",
        "        current_prompt_answer_ref = answer_references_batch[i] # Now correctly indexed\n",
        "        expected_prompt_specific_keywords = current_prompt_answer_ref.get(\"reference_keywords\", [])\n",
        "        expected_prompt_specific_programs = current_prompt_answer_ref.get(\"reference_programs\", [])\n",
        "\n",
        "        # --- REST OF THE FUNCTION LOGIC REMAINS THE SAME ---\n",
        "        format_match = wbi_output_format_regex.search(completion_text.strip())\n",
        "        if format_match:\n",
        "            think_section_content = format_match.group(1).lower().strip()\n",
        "            proposal_section_content = format_match.group(2).lower().strip()\n",
        "\n",
        "            # ... (keyword and program checking logic) ...\n",
        "            for core_keyword in WBI_CORE_CONCEPTS_FOR_REWARD:\n",
        "                 if core_keyword.lower() in proposal_section_content: current_score += 0.05\n",
        "                 elif core_keyword.lower() in think_section_content: current_score += 0.02\n",
        "\n",
        "            for expected_keyword in expected_prompt_specific_keywords:\n",
        "                 if expected_keyword.lower() in proposal_section_content: current_score += 0.4\n",
        "                 elif expected_keyword.lower() in think_section_content: current_score += 0.1\n",
        "\n",
        "            for program_keyword in expected_prompt_specific_programs:\n",
        "                 if program_keyword.lower() in proposal_section_content: current_score += 0.6\n",
        "                 elif program_keyword.lower() in think_section_content: current_score += 0.2\n",
        "\n",
        "            if len(think_section_content) > 50 and len(proposal_section_content) > 100:\n",
        "                current_score += 0.5\n",
        "        else:\n",
        "            current_score -= 1.0\n",
        "\n",
        "        batch_scores.append(min(max(current_score, -2.0), 5.0))\n",
        "        # --- END OF ORIGINAL LOGIC ---\n",
        "\n",
        "    return batch_scores\n",
        "\n",
        "# --- List of reward functions (remains the same) ---\n",
        "wbi_custom_reward_functions = [\n",
        "    reward_wbi_exact_format_adherence,\n",
        "    reward_wbi_approximate_format_presence,\n",
        "    reward_wbi_content_and_evidence,\n",
        "]\n",
        "print(f\"Defined {len(wbi_custom_reward_functions)} reward functions with updated signatures.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sI2oiXsSxFm"
      },
      "source": [
        "Phase 5: Model Training with GRPOTrainer\n",
        "This phase configures and runs TRL's GRPOTrainer using our Unsloth-prepared model, custom WBI dataset, and the reward functions defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQexBU_bS1nP",
        "outputId": "a55c78c4-e223-454f-9216-59dbd8a94cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- GRPO Training Configuration ---\n",
            "Max Sequence Length (Model): 2048\n",
            "Target Max Prompt Length (Config): 550\n",
            "Target Max Completion Length (Config): 1468\n",
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 1 to the `num_generations` of 16\n",
            "\n",
            "Starting WBI GRPO fine-tuning with Unsloth...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 10 | Num Epochs = 75 | Total steps = 150\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 4 x 1) = 64\n",
            " \"-____-\"     Trainable parameters = 13,045,760/1,000,000,000 (1.30% trained)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An error occurred during training: 'list' object has no attribute 'strip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-7-ad391ba4c7b6>\", line 81, in <cell line: 0>\n",
            "    wbi_grpo_trainer.train()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2245, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 315, in _fast_inner_training_loop\n",
            "  File \"<string>\", line 25, in _unsloth_training_step\n",
            "  File \"/content/unsloth_compiled_cache/UnslothGRPOTrainer.py\", line 1034, in _prepare_inputs\n",
            "    output_reward_func = reward_func(prompts=prompts, completions=completions, **reward_kwargs)\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-6-7dbad295b64e>\", line 40, in reward_wbi_exact_format_adherence\n",
            "    match = wbi_output_format_regex.fullmatch(completion_text.strip())\n",
            "                                              ^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'list' object has no attribute 'strip'\n"
          ]
        }
      ],
      "source": [
        "#@title 5.1 Configure and Run GRPOTrainer\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "# import wandb # Uncomment if using Weights & Biases for logging\n",
        "\n",
        "# --- Training Configuration ---\n",
        "# Adjust these parameters based on your Colab resources (GPU type, RAM) and dataset size.\n",
        "num_generations_per_prompt_config = 16  # (K in GRPO paper) Completions per prompt. Higher demands more VRAM. (4-12 typical).\n",
        "per_device_batch_size_config = 1       # Number of PROMPTS processed per device in one optimizer step.\n",
        "gradient_accumulation_steps_config = 4 # Effective batch size = per_device_bs * grad_acc_steps.\n",
        "max_training_steps_config = 150        # For initial testing (e.g., 50-200). For a full run, use num_train_epochs or more steps.\n",
        "                                       # Unsloth's example uses 50 for a quick run. More data needs more steps.\n",
        "learning_rate_config = 5e-6            # Learning rate, often lower for fine-tuning.\n",
        "\n",
        "# Calculate max_prompt_length and max_completion_length for GRPOTrainer.\n",
        "# This is crucial. GRPOTrainer will truncate prompts/completions if they exceed these token limits.\n",
        "# max_prompt_length should accommodate your system + user prompt after tokenization.\n",
        "# max_completion_length is for the generated text (<THINK>...</THINK><PROPOSAL>...</PROPOSAL>).\n",
        "# Ensure: max_prompt_length + max_completion_length <= model.config.max_position_embeddings (or `max_seq_length` used for model loading)\n",
        "\n",
        "# Estimate average tokenized prompt length (can be refined with actual tokenization).\n",
        "# The system prompt can be quite long.\n",
        "avg_tokenized_prompt_len_estimate = 400 # Adjust this based on your data.\n",
        "cfg_max_prompt_len = min(avg_tokenized_prompt_len_estimate + 150, max_seq_length // 2) # Buffer for variability.\n",
        "cfg_max_completion_len = max_seq_length - cfg_max_prompt_len - 30 # Buffer for special tokens, etc.\n",
        "\n",
        "print(f\"--- GRPO Training Configuration ---\")\n",
        "print(f\"Max Sequence Length (Model): {max_seq_length}\")\n",
        "print(f\"Target Max Prompt Length (Config): {cfg_max_prompt_len}\")\n",
        "print(f\"Target Max Completion Length (Config): {cfg_max_completion_len}\")\n",
        "if cfg_max_prompt_len + cfg_max_completion_len > max_seq_length:\n",
        "    print(\"WARNING: Sum of prompt and completion lengths might exceed model's max sequence length!\")\n",
        "\n",
        "wbi_grpo_training_args = GRPOConfig(\n",
        "    output_dir=\"wbi_grpo_unsloth_outputs_run2\", # Change for different runs\n",
        "    learning_rate=learning_rate_config,\n",
        "    optim=\"adamw_torch_fused\",  # Unsloth often recommends for speed with their models.\n",
        "    logging_steps=10,  # Log metrics frequently for observation.\n",
        "    per_device_train_batch_size=per_device_batch_size_config,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps_config,\n",
        "    num_generations=num_generations_per_prompt_config,\n",
        "    max_prompt_length=cfg_max_prompt_len,\n",
        "    max_completion_length=cfg_max_completion_len,\n",
        "    max_steps=max_training_steps_config,  # For quick test; use num_train_epochs for full run (e.g., 1-3).\n",
        "    # num_train_epochs=1, # Uncomment for a full epoch run, and comment out max_steps.\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=max_training_steps_config // 3 if max_training_steps_config >= 60 else max_training_steps_config,\n",
        "    max_grad_norm=0.1,  # Gradient clipping, from Unsloth example.\n",
        "    report_to=\"none\",  # Change to \"wandb\" if using Weights & Biases.\n",
        "    remove_unused_columns=False,  # CRITICAL: Keep \"answer\" column for reward functions.\n",
        "    bf16=torch.cuda.is_bf16_supported(), # Use bfloat16 if available (A100+).\n",
        "    # fp16=not torch.cuda.is_bf16_supported(), # Use float16 if bf16 not available (like on T4).\n",
        "    # load_best_model_at_end=True, # Optional, if using evaluation and want to keep the best model.\n",
        "    # evaluation_strategy=\"steps\", # If eval_dataset is provided.\n",
        "    # eval_steps=50, # How often to evaluate.\n",
        ")\n",
        "\n",
        "# --- Initialize GRPOTrainer ---\n",
        "# Ensure the tokenizer is correctly passed.\n",
        "wbi_grpo_trainer = GRPOTrainer(\n",
        "    model=model,  # Your Unsloth LoRA-adapted model.\n",
        "    tokenizer=tokenizer, # Pass the Unsloth-loaded tokenizer.\n",
        "    args=wbi_grpo_training_args,\n",
        "    reward_funcs=wbi_custom_reward_functions, # Your list of custom WBI reward functions.\n",
        "    train_dataset=train_dataset_wbi,\n",
        "    # eval_dataset=eval_dataset_wbi, # Uncomment if you have an evaluation dataset.\n",
        ")\n",
        "\n",
        "# --- (Optional) Initialize W&B if used ---\n",
        "# project_name_wandb = \"WBI-DoD-GRPO-Unsloth-FineTuning\"\n",
        "# if wbi_grpo_training_args.report_to == \"wandb\":\n",
        "#     try:\n",
        "#         import wandb\n",
        "#         wandb.init(project=project_name_wandb, config=wbi_grpo_training_args)\n",
        "#     except ImportError:\n",
        "#         print(\"wandb not installed. Skipping W&B initialization.\")\n",
        "#         wbi_grpo_training_args.report_to = \"none\"\n",
        "\n",
        "\n",
        "print(\"\\nStarting WBI GRPO fine-tuning with Unsloth...\")\n",
        "try:\n",
        "    wbi_grpo_trainer.train()\n",
        "    print(\"WBI GRPO fine-tuning finished successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during training: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "\n",
        "# --- (Optional) Finish W&B run ---\n",
        "# if wbi_grpo_training_args.report_to == \"wandb\" and wandb.run is not None:\n",
        "#     wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PacjgT1wS3ie"
      },
      "source": [
        "Phase 6: Inference and Saving the Model\n",
        "After training, save your fine-tuned LoRA adapters. Then, test the model's generation capabilities on new prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "miTDoseTS6W4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3575ca3b-611e-406e-bff0-ac4e0229f0a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoRA adapters and tokenizer configuration saved to: wbi_dod_grpo_lora_adapters_final_run2\n",
            "\n",
            "--- Inference Example using Fine-tuned LoRA Model ---\n",
            "\n",
            "Generating response for DoD Prompt:\n",
            "'Explain WBI's unique value proposition as a neutral convener in the Dayton defense ecosystem when tackling complex AFRL challenges.'\n",
            "\n",
            "user\n",
            "You are an expert assistant for the Wright Brothers Institute (WBI), a non-profit 501(c)(3) innovation intermediary.\n",
            "Your task is to generate content to satisfy Department of Defense (DoD) solicitations by creating proposal sections, showcasing WBI's capabilities, experience, and value.\n",
            "Structure your response as follows:\n",
            "1.  First, provide your thinking process and rationale. Enclose this detailed reasoning within <WBI_THINK_START> and <WBI_THINK_END> tags. In this section, explain how WBI's strengths, past projects, and operational model (like \"Discover, Develop, Deliver\") address the user's request.\n",
            "2.  Second, provide the drafted proposal section text. Enclose this formal text within <WBI_PROPOSAL_SECTION_START> and <WBI_PROPOSAL_SECTION_END> tags.\n",
            "\n",
            "When generating content:\n",
            "-   Accurately reflect WBI's mission to accelerate solutions for the warfighter by uniting end-users, technologists, acquirers, and experts from industry and academia.\n",
            "-   Emphasize WBI's cornerstone Partnership Intermediary Agreement (PIA) with the Air Force Research Laboratory (AFRL).\n",
            "-   Incorporate relevant WBI programs (e.g., Software Defined Radio University Challenge, SDR University Challenge, SDR Challenge), partnerships (e.g., AFRL, AFLCMC, NSWC Crane), and core capabilities (e.g., rapid prototyping, technology transfer, commercialization, multi-sector collaboration).\n",
            "-   Highlight WBI's role as a neutral convener and agile facilitator in the Dayton, Ohio, defense ecosystem and beyond.\n",
            "-   Cite specific WBI initiatives or achievements as evidence where appropriate, drawing from WBI's established record and programs.\n",
            "\n",
            "\n",
            "Explain WBI's unique value proposition as a neutral convener in the Dayton defense ecosystem when tackling complex AFRL challenges.\n",
            "model\n",
            "Okay, hereâ€™s a draft proposal section for a DoD solicitation, crafted to meet the requirements and highlighting WBIâ€™s strengths. Letâ€™s break down my thinking and reasoning, followed by the final proposal text.\n",
            "\n",
            "**<WBI_THINK_START>**\n",
            "\n",
            "My primary thinking here is to position WBI as *the* strategic partner for the DoD, particularly in navigating complex AFRL challenges and fostering innovation.  Weâ€™re not just a service provider; weâ€™re a facilitator, a collaborator, and a trusted source of expertise.  The core of our value proposition lies in our ability to seamlessly connect disparate stakeholders â€“ AFRL, industry, academia, and government â€“ to rapidly generate and validate novel solutions.  Weâ€™ll emphasize our proactive, partnership-driven approach, leveraging our established relationships and specialized capabilities to accelerate the pace of innovation.  Crucially, our PIA with the AFRL provides a robust framework for collaboration and accountability.  Weâ€™ll demonstrate through concrete examples how weâ€™ve successfully navigated complex defense challenges and delivered tangible results â€“ focusing on rapid prototyping, technology transfer, and strategic commercialization.  Weâ€™ll position ourselves as a neutral, trusted hub, minimizing risk and maximizing value for the DoDâ€™s strategic objectives.  Ultimately, WBI will be recognized as the leading partner for driving innovation and ensuring a competitive advantage in the defense sector.  Weâ€™ll tailor the language and specific examples to the *precise* solicitation requirements outlined â€“ which Iâ€™ll need to review to ensure maximum effectiveness.\n",
            "\n",
            "**<WBI_PROPOSAL_SECTION_START>**\n",
            "\n",
            "**Proposal Section: Leveraging WBI to Accelerate AFRL Innovation and Strategic Partnerships**\n",
            "\n",
            "**1. Executive Summary**\n",
            "\n",
            "WBI is a leading non-profit organization dedicated to accelerating solutions for the warfighter through the unification of end-users, technologists, acquirers, and experts across the defense ecosystem.  Our core strength lies in our proven partnership model, facilitated by our established relationship with the Air Force Research Laboratory (AFRL), and our ability to rapidly prototype, transfer, and commercialize innovative technologies.  We offer a collaborative, agile approach to complex defense challenges, consistently delivering tangible results and fostering strategic partnerships.  This proposal outlines how WBI will strategically contribute to the AFRLâ€™s mission and drive a sustainable competitive advantage.\n",
            "\n",
            "**2. WBIâ€™s Core Capabilities and Value Proposition**\n",
            "\n",
            "WBI distinguishes itself through a unique approach: **The Dayton Partnership Accelerator.** This model, built upon the foundation of our longstanding partnership with the AFRL, allows us to:\n",
            "\n",
            "*   **Rapid Prototyping & Proof-of-Concept Development:**  We provide rapid prototyping services, utilizing our team of experienced engineers and designers to rapidly develop and test novel technologies.  This includes specialized capabilities in [mention specific prototyping skills â€“ e.g., embedded systems, signal processing, sensor integration].\n",
            "*   **Strategic Technology Transfer & Commercialization:**  We facilitate the transfer of proven technologies from the lab to the field, working with AFRL and industry partners to identify and validate high-value opportunities.  Weâ€™ve successfully partnered with [mention specific partners â€“ e.g., AFLCMC, NSWC Crane] to [briefly describe the nature of the partnership â€“ e.g., accelerate the development of advanced sensor systems, optimize existing defense systems].\n",
            "*   **Collaborative Problem Solving:** Our team of experts â€“ including [mention key personnel and expertise â€“ e.g., software engineers, systems analysts, regulatory compliance specialists] â€“ excels at facilitating cross-functional collaboration and identifying novel solutions. We facilitate workshops, conduct needs assessments, and translate complex technical requirements into actionable strategies.\n",
            "*   **Neutral Convener & Agile Facilitation:**  WBI acts as a neutral convener, bringing together diverse stakeholders â€“ AFRL researchers, industry partners, government officials, and potential investors â€“ to ensure alignment and maximize value.  We employ agile methodologies â€“ Agile, Scrum, etc. â€“ to streamline the innovation process and manage project scope.  Our experienced facilitators ensure efficient communication and effective decision-making.\n",
            "\n",
            "**3.  Case Studies & Successes**\n",
            "\n",
            "*   **AFRLâ€™s [Project Name] â€“ Rapid Prototype Development:**  WBI spearheaded the development of a novel [type of technology] prototype for [specific defense application] utilizing AFRLâ€™s expertise.  This resulted in a [quantifiable result â€“ e.g., 30% reduction in operational costs, improved threat detection rate] and secured a potential contract with [mention a significant partner].\n",
            "*   **AFLCMC Partnership â€“ Advanced Sensor Integration:**  Through our partnership with AFLCMC, we successfully integrated a [specific sensor technology] into the [specific defense system], enhancing situational awareness and improving response times. This resulted in [quantifiable result â€“ e.g., a 15% reduction in false alarms].\n",
            "*   **NSWC Crane Collaboration â€“ Cybersecurity Enhancement:**  WBI facilitated a collaborative project between AFRL and NSWC Crane to develop and deploy a novel cybersecurity solution for [specific defense system]. This resulted in a demonstrable reduction in vulnerabilities and enhanced protection against [specific threat].\n",
            "\n",
            "**4.  WBIâ€™s PIA and Commitment to the Defense Ecosystem**\n",
            "\n",
            "Our Partnership Intermediary Agreement (PIA) with the AFRL provides a structured framework for collaboration, ensuring accountability and clear lines of communication.  We are deeply committed to fostering a collaborative and transparent defense ecosystem.  We actively participate in industry events and contribute to relevant DoD initiatives.  Our commitment to ethical and responsible innovation is paramount.\n",
            "\n",
            "**5.  Call to Action**\n",
            "\n",
            "WBI is uniquely positioned to accelerate innovation and strengthen the defense ecosystem.  We invite the DoD to partner with us to leverage our expertise, foster strategic partnerships, and drive a sustainable competitive advantage.  We are confident that our collaborative approach, combined with our proven capabilities, will deliver significant and measurable results.\n",
            "\n",
            "---\n",
            "\n",
            "**To help me refine this proposal further, could you tell me:**\n",
            "\n",
            "*   **What specific DoD solicitation are you targeting?** (e.g., specific program, budget area)\n",
            "*   **Are there any specific technologies or areas of focus the solicitation emphasizes?**\n",
            "*   **Do you have any specific metrics youâ€™d like to highlight (e.g., cost savings, risk reduction, operational efficiency)?**\n",
            "*   **Are there any particular partnerships youâ€™d like to emphasize?** (AFRL, AFLCMC, NSWC, etc.)\n",
            "\n",
            "\n",
            "--- End of Inference Example ---\n"
          ]
        }
      ],
      "source": [
        "#@title 6.1 Save LoRA Adapters and Perform Inference\n",
        "\n",
        "# --- Save LoRA Adapters and Tokenizer ---\n",
        "# This saves only the learned LoRA weights, not the full model.\n",
        "lora_output_directory = \"wbi_dod_grpo_lora_adapters_final_run2\" # Change for different runs\n",
        "model.save_pretrained(lora_output_directory)\n",
        "tokenizer.save_pretrained(lora_output_directory)\n",
        "print(f\"LoRA adapters and tokenizer configuration saved to: {lora_output_directory}\")\n",
        "\n",
        "# --- Inference with the Fine-tuned Model ---\n",
        "# The `model` variable in this session currently holds the LoRA-adapted fine-tuned model.\n",
        "from transformers import TextStreamer\n",
        "import gc # Garbage collector\n",
        "\n",
        "print(\"\\n--- Inference Example using Fine-tuned LoRA Model ---\")\n",
        "\n",
        "# Example DoD-style prompt for testing inference\n",
        "test_dod_prompt_for_inference = \"Explain WBI's unique value proposition as a neutral convener in the Dayton defense ecosystem when tackling complex AFRL challenges.\"\n",
        "\n",
        "# Format the prompt using the chat template, including the system prompt\n",
        "inference_chat_messages_list = [\n",
        "    {\"role\": \"system\", \"content\": wbi_system_prompt_content},\n",
        "    {\"role\": \"user\", \"content\": test_dod_prompt_for_inference},\n",
        "]\n",
        "\n",
        "# Apply chat template to prepare the input text for the model\n",
        "# `add_generation_prompt=True` is crucial for instruction-tuned models.\n",
        "inference_input_text_formatted = tokenizer.apply_chat_template(\n",
        "    inference_chat_messages_list,\n",
        "    add_generation_prompt=True,\n",
        "    tokenize=False, # Get the string first\n",
        ")\n",
        "\n",
        "# Tokenize the formatted prompt string\n",
        "# Ensure the model and inputs are on the same device (usually \"cuda\" if GPU is available).\n",
        "device = model.device\n",
        "inference_tokenized_inputs = tokenizer(inference_input_text_formatted, return_tensors=\"pt\").to(device)\n",
        "\n",
        "print(f\"\\nGenerating response for DoD Prompt:\")\n",
        "print(f\"'{test_dod_prompt_for_inference}'\\n\")\n",
        "\n",
        "# Use a TextStreamer for real-time output if desired.\n",
        "# Ensure tokenizer is passed correctly if it has special tokens for skipping.\n",
        "text_streamer_for_inference = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "# Clear some memory before generation if needed, especially on constrained environments\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Generate text\n",
        "try:\n",
        "    with torch.no_grad(): # Important for inference to save memory and speed up\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=inference_tokenized_inputs.input_ids,\n",
        "            attention_mask=inference_tokenized_inputs.attention_mask,\n",
        "            max_new_tokens=cfg_max_completion_len,  # Allow enough tokens for THINK + PROPOSAL_SECTION\n",
        "            temperature=0.5,  # Lower for more factual/deterministic, higher for creative.\n",
        "            top_p=0.9,        # Nucleus sampling.\n",
        "            do_sample=True,   # Enable sampling for diverse outputs. Set to False for greedy.\n",
        "            streamer=text_streamer_for_inference,\n",
        "            pad_token_id=tokenizer.eos_token_id # Crucial for consistent generation.\n",
        "        )\n",
        "    # The TextStreamer prints the output. If not using streamer, decode `generated_ids`.\n",
        "    # decoded_output = tokenizer.decode(generated_ids[0, inference_tokenized_inputs.input_ids.shape[-1]:], skip_special_tokens=True)\n",
        "    # print(decoded_output)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during inference: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\n--- End of Inference Example ---\")\n",
        "\n",
        "\n",
        "# --- (Optional) Merging LoRA and Saving for Deployment ---\n",
        "# Unsloth provides methods to merge LoRA weights with the base model for standalone deployment.\n",
        "# This creates a larger model file but doesn't require PEFT library at inference time.\n",
        "# Refer to official Unsloth documentation for `save_pretrained_merged` and `save_pretrained_gguf`.\n",
        "\n",
        "# Example for saving a merged float16 model:\n",
        "# merged_model_dir_float16 = \"wbi_dod_grpo_merged_model_float16_run2\"\n",
        "# should_save_merged_model = False  # Set to True to execute this block\n",
        "# if should_save_merged_model:\n",
        "#     print(f\"\\nMerging LoRA adapter and saving full model to float16 at: {merged_model_dir_float16}\")\n",
        "#     # Important: Ensure model is not loaded in 4-bit/8-bit if you want a true float16/bfloat16 merge.\n",
        "#     # You might need to reload the base model in full precision, then apply adapters, then merge.\n",
        "#     # Or, Unsloth's `save_pretrained_merged` might handle dequantization. Check their docs.\n",
        "#     try:\n",
        "#         # For Unsloth, you might need to reload the model without 4-bit, then apply adapter and merge.\n",
        "#         # This is a simplified example; actual steps for unquantized merge might vary.\n",
        "#         # If model is already FastModel with LoRA:\n",
        "#         model.save_pretrained_merged(merged_model_dir_float16, tokenizer, save_method=\"merged_16bit\")\n",
        "#         print(f\"Merged float16 model saved to {merged_model_dir_float16}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error during merged model saving: {e}\")\n",
        "\n",
        "# Example for saving to GGUF format (for llama.cpp, etc.):\n",
        "# gguf_output_file_name = \"wbi_dod_grpo_merged_q8_0_run2.gguf\" # Note: GGUF path is often a filename\n",
        "# should_save_gguf_model = False # Set to True to execute\n",
        "# if should_save_gguf_model:\n",
        "#     print(f\"\\nSaving model to GGUF format (Q8_0) as: {gguf_output_file_name}\")\n",
        "#     try:\n",
        "#         # Ensure model is in a state suitable for GGUF conversion (e.g., merged).\n",
        "#         model.save_pretrained_gguf(gguf_output_file_name, tokenizer, quantization_method=\"q8_0\")\n",
        "#         print(f\"GGUF Q8_0 model saved as {gguf_output_file_name}\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error during GGUF model saving: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh0EIFJwTFJe"
      },
      "source": [
        "Phase 7: Concluding Remarks and Next Steps\n",
        "Text Cell:\n",
        "\n",
        "This Colab notebook provides a comprehensive template for fine-tuning a language model using Unsloth and GRPO, tailored for generating WBI-specific DoD proposal content.\n",
        "\n",
        "Key Next Steps and Considerations:\n",
        "\n",
        "Expand Your Dataset: The quality and quantity of your wbi_dod_prompts_with_references dataset are paramount. Aim for hundreds, if not thousands, of diverse and high-quality examples that accurately reflect the types of queries in DoD solicitations and the corresponding relevant WBI information.\n",
        "Iterate on Reward Functions: This is the most art-and-science part of GRPO. Continuously test and refine your wbi_custom_reward_functions. Adjust scoring weights, add new reward components (e.g., for conciseness, avoiding repetition, or stronger evidence linkage), and ensure they align with your definition of a \"good\" proposal section.\n",
        "Hyperparameter Tuning: Experiment with learning_rate, LoRA parameters (r, lora_alpha), num_generations, batch sizes, and the number of training steps (max_steps or num_train_epochs). Use Weights & Biases (W&B) or similar tools to track experiments and identify optimal configurations.\n",
        "Thorough Evaluation: Beyond the automated reward scores from GRPO, perform rigorous human evaluation of the generated outputs. Subject Matter Experts (SMEs) in proposal writing and WBI's operations should review the content for factual accuracy, relevance, persuasiveness, coherence, and adherence to the desired tone and style.\n",
        "Memory Management (Colab): Continuously monitor VRAM usage in Colab. If you encounter Out-Of-Memory (OOM) errors, try:\n",
        "Reducing max_seq_length.\n",
        "Decreasing num_generations_per_prompt_config.\n",
        "Lowering per_device_batch_size_config (though gradient_accumulation_steps_config can help maintain effective batch size).\n",
        "Using smaller base models if necessary.\n",
        "Ensuring 4-bit quantization is active (load_in_4bit=True).\n",
        "Consult Unsloth Documentation: The Unsloth library is actively developed. Always refer to the official Unsloth GitHub repository and documentation for the latest installation instructions, API changes, new features, and best practices for fine-tuning and deployment."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPObKdfBCnNLiYqgNOKbYi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f845bcac9c9745f0870c37ae40333f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41348491aa914f4aba163acf23d32897",
              "IPY_MODEL_c3ba29eedc14423b8574c2e114010542",
              "IPY_MODEL_da267cf76c1b4474827271ff284c5eac"
            ],
            "layout": "IPY_MODEL_c7ff4c5007c54002a98471daa7228959"
          }
        },
        "41348491aa914f4aba163acf23d32897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d6eb46690648b49bcf9ece7314e7ba",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_42e1255321434f618bd5a6fa79724c22",
            "value": "Map:â€‡100%"
          }
        },
        "c3ba29eedc14423b8574c2e114010542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04b07403d3764135b3e399ad9fd9ec45",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06dbfc840afd4568a1c300d4c761b0e1",
            "value": 10
          }
        },
        "da267cf76c1b4474827271ff284c5eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca2ea736bd847e58e626e63773b3040",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_59d746e2c6684ca5bbcf8dd209d12d9e",
            "value": "â€‡10/10â€‡[00:00&lt;00:00,â€‡605.51â€‡examples/s]"
          }
        },
        "c7ff4c5007c54002a98471daa7228959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d6eb46690648b49bcf9ece7314e7ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e1255321434f618bd5a6fa79724c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04b07403d3764135b3e399ad9fd9ec45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06dbfc840afd4568a1c300d4c761b0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ca2ea736bd847e58e626e63773b3040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d746e2c6684ca5bbcf8dd209d12d9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}